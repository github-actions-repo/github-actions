# Release Your Software with GitHub Actions

In this final chapter, we will dive into using GitHub Actions for **continuous deployments (CDs)**. We will create a container with a simple website that uses the package from Chapter 6, Build and Validate Your Code, and we will deploy it to Kubernetes in the cloud, securing access with **OpenID Connect (OIDC)**. We will use environments to secure the deployment and concurrency groups to control the flow of multiple workflows.

We will use Microsoft **Azure Kubernetes Service (AKS)** in this chapter as the production environment, but I will point you to documentation to carry out the same recipes with other cloud providers such as **Google Kubernetes Engine (GKE)** on **Google Cloud Platform (GCP)** or **Elastic Container Services (ECSs)** on **Amazon Web Services (AWS)**.

We’ll cover the following recipes:

> * Building and publishing a container
> * Using OIDC to securely deploy to any cloud
> * Environment approval checks
> * Releasing the container application to **Azure Kubernetes Service (AKS)**
> * Automating the update of your dependencies

## Technical requirements

For this chapter, you will need **Docker**, **Node.js**, and the **GitHub CLI**, either on your local machine, or you can just use **GitHub Codespaces**. For the Microsoft Azure part, you will need an Azure account. If you don’t have one, just create a free trial account here: https://azure.microsoft.com/en-us/free. You can use the Azure CLI locally or just use **Cloud Shell** in the **Azure portal**.

You will also need a GitHub **personal access token (PAT)** with read and write permission for GitHub packages (https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-personal-access-token-classic).

---

## Building and publishing a container

In this recipe, we are going to containerize a simple web application and push it to a container registry.

### Getting ready...

Open the repository (https://github.com/wulfland/release-recipe) and click on Use this template to create a new copy out of it (direct link: https://github.com/new?template_name=release-recipe&template_owner=wulfland). Create a new public repository in your personal account, name it release-recipe, and clone the repository.

Open the package.json and adjust the author and repository URL.

Under dependencies, adjust the owner and version of the package recipe to your package from Chapter 6, Build and validate your code:

```js
"dependencies": {
  "@wulfland/package-recipe": "^2.0.5",
  "express": "^4.18.2"
}
```

Replace the owner in the file .npmrc:

```sh
@wulfland:registry=https://npm.pkg.github.com
```

In a terminal, run the following commands:

```sh
npm login --registry https://npm.pkg.github.com
```

Enter your GitHub username and the PAT token with access to packages. Run the following commands:

```sh
npm install
npm start
> release-recipe@1.0.0 start
> node src/index.js
Server running at http://localhost:3000
```

Now, you should have a Node.js application running on port 3000. Open a browser, navigate to http://localhost:3000, and validate that is displays Hello World!. Stop the server by exiting the process (CTRL+C).

### How to do it...

Create a new file, Dockerfile, in the root of the repository. Inherit your image from the node image and pick the 21-bullseye version. Create a folder, copy the repository content in it, and make it the working folder:

```Dockerfile
FROM node:21-bullseye
RUN mkdir -p /app
COPY . /app
WORKDIR /app
```

Note that you have to run npm install before building the Docker image to avoid storing your credentials in the container. Rebuild the npm package in the container:

```Dockerfile
RUN npm rebuild
```

Expose port 3000 of our express website and run npm start as the start command of the container:

```Dockerfile
EXPOSE 3000
CMD [ "npm", "start"]
```

Next, build your container image locally and run it:

```sh
npm install
docker build -t hello-world-recipe .
docker run -it -p 3000:3000 hello-world-recipe
```

Verify that the website runs on port 3000 on your local machine again.
Create a new workflow .github/workflows/publish.yml. Run it on pull requests and pushes to the main branch:

```yml
name: Publish Docker Image
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
```

Set the registry name and image name as environment variables:

```yml
env:
  REGISTRY: 'ghcr.io'
  IMAGE_NAME: '${{ github.repository }}'
```

Add a job with permissions for GITHUB_TOKEN to write packages and read content:

```yml
jobs:
  build-and-push-image:
    runs-on: ubuntu-latest
    permissions:
      packages: write
      contents: read
```

Add the following steps. Check out the repository and log in to the Docker registry:

```yml
- name: Checkout repository
  uses: actions/checkout@v4
- name: Log in to the Container registry
  uses: docker/login-action@v3
  with:
    registry: ${{ env.REGISTRY }}
    username: ${{ github.actor }}
    password: ${{ secrets.GITHUB_TOKEN }}
```

Extract the metadata for the image from the registry. We use the long SHA as the tag for the container. Give the step an id to later access the output:

```yml
- name: Extract metadata (tags, labels) for Docker
  id: meta
  uses: docker/metadata-action@v5
  with:
    images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
    tags: |
      type=sha,format=long
```

Set up Node.js to use the correct version and registry. Then, build and test your code. You have to set the NODE_AUTH_TOKEN environment variable to the GITHUB_TOKEN to authenticate to the package registry and receive the npm package from the package recipe from Chapter 6:

```yml
- uses: actions/setup-node@v4
  with:
    node-version: 21.x
    registry-url: https://npm.pkg.github.com/
- name: Build and test
  env:
    NODE_AUTH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  run: |
    npm install
    npm run test
```

Now, we are ready to build and push the Docker image. Use the output of the meta step to set the tags and labels:

```yml
- name: Build and push Docker image
  uses: docker/build-push-action@v5
  with:
    context: .
    push: ${{ github.event_name != 'pull_request' }}
    tags: ${{ steps.meta.outputs.tags }}
    labels: ${{ steps.meta.outputs.labels }}
```

Commit and push your changes. After the workflow run, you will find the Docker image on the Code tab of your repository on the right side under Packages.

### How it works...

I use Express (https://expressjs.com/) as a simple web framework to run a website. The website displays the content from our package; we’ll leverage this in the upcoming recipes to automatically keep our dependencies up to date. The code is easy to understand:

```js
const express = require('express');
const greet = require('@wulfland/package-recipe/src/index')
const app = express();
const port = 3000;
app.get('/', (req, res) => {
  res.send(greet());
});
app.listen(port, () => {
  console.log(`Server running at http://localhost:${port}`);
});
```

This time, I have omitted all linting and testing, as we have covered this already in Chapter 6. We need to containerize this application to deploy it to the cloud later.

To deploy a container to the cloud, you have to store it in a container registry. We are using GitHub packages here, but using the cloud-specific registries works the same way. You just have to configure a PAT token and cannot use GITHUB_TOKEN, but this is the only difference.

### There’s more...

The Docker meta-action (https://github.com/docker/metadata-action) can be used to extract metadata from Git references and GitHub events. Just as for GitVersion in Chapter 6, it can be used to automate the versioning of your containers. It also supports semantic versioning:

```yml
- name: Docker meta
  id: meta
  uses: docker/metadata-action@v5
  with:
    images: |
      ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
    tags: |
      type=ref,event=branch
      type=ref,event=pr
      type=semver,pattern={{version}}
      type=semver,pattern={{major}}.{{minor}}
```

In our example, we just use the Git SHA to be able to deploy every commit, but you can easily extend the versioning according to your workflow.

Using OIDC to securely deploy to any cloud
In this recipe, we will set up our Kubernetes cluster in Azure, and we will configure OIDC in Azure to deploy to the cluster without using stored secrets.

### Getting ready...

Make sure you have a PAT with at least read access to packages.

If you are experienced in Azure and you have the Azure CLI (https://docs.microsoft.com/cli/azure/install-azure-cli?view=azure-cli-latest) installed locally, then you can work from there. If you are new to Azure or you don’t have the CLI installed, just use Azure Cloud Shell at https://shell.azure.com.

Set the PAT token as an environment variable:

```sh
export GHCR_PAT=<YOUR_PAT_TOKEN>
```

The token will be used by Kubernetes to read from the GitHub Package Registry. Open the script setup-azure.sh and adjust the location variable at the top of the file to the Azure region of your choice. You can get a list of regions using az account list-locations -o table. Commit and push your changes, and then run the script:

```sh
git clone https://github.com/{OWNER}/release-recipe.git
cd release-recipe
chmod +x setup-azure.sh
./setup-azure.sh
```

This will create an Azure Kubernetes Service and connect it with the GitHub Container registry. While the script runs, you can configure OIDC to access it from the workflow.

### How to do it...

Use Cloud Shell or a local terminal and create a new app registration:

```sh
az ad app create --display-name release-recipe
```

Then create a service principle using app ID from the registration output:

```sh
az ad sp create --id <appId>
```

Then, open the Azure portal, and in Microsoft Entra, find release-recipe under App registrations. Add the OIDC trust under Certificates & secrets | Federated credentials | Add credentials. Fill out the form. Set the organization to your GitHub username, enter the repository name, and pick Environment as the entity type (see Figure 7.1):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_07_1.jpg)<br>
Figure 7.1 – Connecting your GitHub account in Microsoft Entra

Give the credentials a name and click Add. Note the Application (client) ID and Directory (tenant) ID of the release-recipe application (see Figure 7.2). You will need that later:

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_07_2.jpg)<br>
Figure 7.2 – Client and Tenant IDs from the app registration

Then, assign the service principle a role in your subscription. Open the subscription in the portal. Under Access control (IAM) | Role assignment | Add | Add role assignment, follow the wizard. Select role—for example, Contributor—and click Next. Select User, group, or service principal, and select the service principle you created earlier.

### How it works...

Instead of using credentials stored as secrets to connect to a cloud provider, such as Azure, AWS, GCP, or HashiCorp, you can use OIDC. OIDC will exchange short-lived tokens for authentication instead of credentials. Your cloud provider also needs to support OIDC on their end.

When using OIDC, you don’t have to store cloud credentials in GitHub, you have more granular control over what resources the workflow can access, and you have rotating, short-lived tokens that will expire after the workflows run. Figure 7.3 shows an overview of how OIDC works:

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_07_3.jpg)<br>
Figure 7.3 – OIDC integration with a cloud provider

The steps are the following:

Create an OIDC trust between your cloud provider and GitHub. Limit the trust to an organization and repo and further limit access to an environment, branch, or pull request.
The GitHub OIDC provider auto-generates a JSON web token during a workflow run. The token contains multiple claims to establish a secure and verifiable identity for the specific workflow job.
The cloud provider validates the claims and provides a short-lived access token that is available only for the lifetime of the job.
The access token is used to access resources that the identity has access to.
You can use the identity to directly access resources, or you can use it to get credentials from a secure vault (such as Azure Key Vault or HashiCorp Vault). In this way, you can safely connect to services that do not support OIDC and automated secret rotation by using the vault.

In GitHub, you can find instructions on configuring OIDC for AWS, Azure, and GDP at https://docs.github.com/en/actions/deployment/security-hardening-your-deployments.

Environment approval checks
We have already used environments in Chapter 5, Automate tasks in GitHub with GitHub Actions, so this is a repetition. Therefore, I’ll keep the recipe rather short. Environments manage core releases, and we will use them in the following recipes to display the URL of our service in Kubernetes.

### Getting ready...

Make sure you have the Application (client) ID, Directory (tenant) ID, and Subscription ID from the previous chapters at hand. The subscription ID can be obtained by using the following:

```sh
az account show
```

### How to do it...

1. In the settings of your repositories, go to **Environments**, click **New environment**, and create a new environment: `Production`.
2. Add main as the deployment branch.
3. Add a new **Environment secret** called `AZURE_CLIENT_ID` and set it to the **Application (client) ID**.
4. Add a new **Environment secret** called `AZURE_TENANT_ID` and set it to the **Directory (tenant) ID**.
5. Add a new **Environment secret** called `AZURE_SUBSCRIPTION_ID` and set it to the **Subscription ID**.
6. Add a new **Environment secret** called `AZURE_CLUSTER_NAME` and set it to the name of the cluster (`AKSCluster` if you did not modify the `setup-azure.sh` script).
7. Add a new **Environment secret** called `AZURE_RESOURCE_GROUP` and set it to the name of the resource group (`AKSCluster` if you did not modify the `setup-azure.sh` script).

We will use these environment secrets in the next recipe to securely deploy to Kubernetes in the cloud.

### How it works...

Environments add a layer of abstraction over a job in a workflow, and they can be protected by rules. See Chapter 5, *Automate Tasks in GitHub with GitHub Actions*, for more details on approval checks. Environments can also be trusted by OIDC entities, and this is what we are going to use in the next recipe.

---

## Releasing the container application to AKS

Now, it is time to release our application to the production environment in AKS.

### Getting ready...

Open the file `.github/workflows/publish.yml`.

### How to do it...

1. Add two more environment variables to the top of the workflow:

   ```yml
   env:
     REGISTRY: 'ghcr.io'
     IMAGE_NAME: '${{ github.repository }}'
     APP_NAME: 'release-recipe-app'
     SERVICE_NAME: 'release-recipe-service'
   ```

   Add an output to the job `build-and-push-image` from the previous recipe so that the new job will be able to access the image name:

   ```yml
   outputs:
     image_tag: ${{ fromJSON(steps.meta.outputs.json).tags[0] }}
   ```

2. Add a second job called `production` to the workflow, which only runs on pushes to `main` and is associated with the production environment. Set the URL of the environment to the output of a step we’ll add later. The job will need the permissions `id-token: write` and `content: read` for OIDC to work:

```yml
production:
  if: github.ref == 'refs/heads/main' && github.event_name == 'push'
  needs: build-and-push-image
  runs-on: ubuntu-latest
  permissions:
    id-token: write
    contents: read
  environment:
    name: Production
    url: ${{ steps.get-service-url.outputs.SERVICE_URL}}
```

3. Add steps to check out the repository and log into Azure using OIDC:

```yml
- name: Checkout
  uses: actions/checkout@v4
- name: 'Az CLI login'
  uses: azure/login@v1
  with:
    client-id: ${{ secrets.AZURE_CLIENT_ID }}
    tenant-id: ${{ secrets.AZURE_TENANT_ID }}
    subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
```

Set the context for the Kubernetes deployments:

```yml
- name: 'Az CLI set AKS context'
  uses: azure/aks-set-context@v3
  with:
    cluster-name: ${{ secrets.AZURE_CLUSTER_NAME }}
    resource-group: ${{ secrets.AZURE_RESOURCE_GROUP }}
```

Inspect the file service.yml. It deploys a LoadBalancer that displays port 3000 of our application on port 80. Additionally, inspect deployment.yml, which contains the definition of our application. To replace the environment variables in the files, we use envsubst. We then pipe the result to kubectl and apply the manifest files:

```yml
- name: Deploy
  env:
    IMAGE: ${{ needs.build-and-push-image.outputs.image_tag }}
  run: |-
    envsubst < service.yml | kubectl apply -f -
    envsubst < deployment.yml | kubectl apply -f -
```

Get the URL of the service in Kubernetes using kubectl describe service and set it as a step output to be available in the production environment URL:

```yml
- name: 'Get Service URL'
  id: get-service-url
  run: |
    IP=$(kubectl describe service $SERVICE_NAME| grep "LoadBalancer Ingress: " | awk '{print $3}')
    echo "SERVICE_URL=http://$IP" >> $GITHUB_OUTPUT
```

Finally, we want to check if the deployment was successful. If the application would have a /health endpoint, then we would query that, but because out app is very simple, we’ll just rely on the returned status code:

```yml
- name: 'Run smoke test'
  env:
    SERVICE_URL: ${{ steps.get-service-url.outputs.SERVICE_URL}}
  run: |
    status=`curl -s --head $SERVICE_URL | head -1 | cut -f 2 -d' '`
    if [ "$status" != "200" ]
    then
      echo "Wrong HTTP Status. Actual: '$status'"
      exit 1
    fi
```

What this snippet does is query the header of the website with curl --head. The -s switch suppresses other output. It then takes the first line using head -1. The line looks like HTTP/1.1 200 OK. We cut the string by using blanks and take the second element (the status code). If the status code is not 200 (OK), it raises an exception.

Commit and push your changes to the main branch. This will trigger the workflow; this will push a new version of the container to the registry and publish it from there in AKS. Follow the URL of the service (see Figure 7.4) and verify that the website is displayed correctly:

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_07_4.jpg)<br>
Figure 7.4 – Deploy to dynamic environments

It will display the Hello World application from your container.

### How it works...

The Azure Login action will authenticate to Azure using the OIDC identity. This identity can then be granted fine-grained access to Azure resources. As we limited access to the Production environment in our repository, only this job can use the application to authenticate to Azure. You could also use branches, tags, or pull requests for that.

We then use the aks-set-context action to configure access to AKS using kubectl. This will allow us to deploy the actual application to Kubernetes.

### There’s more...

Kubernetes can get very complex very fast. In the real world, you are going to add DNS and SSL to the cluster and use namespaces to manage multiple containers running in parallel. This is a nice way to deploy every pull request to a dynamic environment. However, this is outside the scope of this book.

If you want to use other cloud providers instead of Azure to release the container, you’ll find a hands-on for deploying to AWS Elastic Container Service (ECS) here: https://github.com/wulfland/AccelerateDevOps/blob/main/ch9_release/Deploy_to_AWS_ECS.md, or another on how to deploy to Google Kubernetes Engine (GKE) here: https://github.com/wulfland/AccelerateDevOps/blob/main/ch9_release/Deploy_to_GKE.md.

---

## Automating the update of your dependencies

Now that we have an end-to-end workflow from our package repo into the release repo and, from there, into production, I want to show you how you can use dependabot together with GitHub Actions to automate the update process of your dependencies.

### Getting ready...

In the repository, navigate to Settings | Code security and analysis and make sure that Dependency graph is enabled (see Figure 7.4):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_07_5.jpg)<br>
Figure 7.5 – Enabling the dependency graph and optional dependabot alerts

This will analyze your repository and detect all dependencies that you can inspect under Insights | Dependency graph. You can also enable Dependabot alerts. In this case, dependabot will notify you when there are known vulnerabilities in one of your dependencies. Dependabot security updates go one step further, and dependabot will generate a pull request with a version update to a nonvulnerable version for you. To reduce the number of pull requests, you can group the updates together (this feature is still in beta).

### How to do it...

Create a new dependabot secret called PAT and set it with the value of the PAT token with read access to packages:

```sh
gh secret set PAT --app dependabot
```

Create a new file: .github/dependabot.yml. It always starts with version:2:

```yml
version: 2
```

Configure a new npm-registry using PAT, pointing to https://npm.pkg.github.com:

```yml
registries:
  npm-pkg:
    type: npm-registry
    url: https://npm.pkg.github.com
    token: ${{ secrets.PAT }}
    replaces-base: true
```

The version updates are configured under updates. Add the ecosystem npm and point it to the name of the registry you created:

```yml
updates:
  - package-ecosystem: "npm"
    directory: "/"
    schedule:
      interval: "weekly"
    registries:
      - npm-pkg
```

This will check for weekly updates of npm packages, including those in the private registry.

Optionally, add updates for GitHub actions:

```yml
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
```

This will check the GitHub actions for updated versions.

You can also add Docker as an ecosystem:

```yml
  - package-ecosystem: "docker"
    directory: "/"
    schedule:
      interval: "weekly"
```

This also works with Kubernetes manifest files, and dependabot will check for updates in image tags inside the manifest file. However, in our case, we use environment variables to directly deploy the new version.

Commit and push the file. Then, head over to Insights | Dependency graph | Dependabot. There is an entry for every ecosystem configured, and you can inspect the logfile by clicking on the link on the right side (see Figure 7.6):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_07_6.jpg)<br>
Figure 7.6 – Inspecting the logs for dependabot version updates

Check that there are no errors in the logs.

Now, go to the package-recipe repository and create a new release with a new patch version. Once the new package version is published, head over to Insights | Dependency graph | Dependabot and click on the link in the package.json line. Hit Check for updates to enforce dependabot to now check for updates (see Figure 7.7):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_07_7.jpg)<br>
Figure 7.7 – Have dependabot now check for updates

Dependabot will create a new pull request with a version update to the new version (see Figure 7.8):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_07_8.jpg)<br>
Figure 7.8 – A pull request created by dependabot version updates

Merge the pull request or have dependabot do it by commenting @dependabot squash and merge on the pull request.

As we trust the owner of the package, we can automate this last step and just merge every pull request for specific versions after all checks are successful. Create a new file: .github/workflows/dependencies.yml. The workflow will run on pull_request_target, and it will need write permissions for the pull requests:

```yml
name: Dependabot auto-merge
on: [ pull_request_target ]
permissions:
  pull-requests: write
  contents: write
```

Only run the job if the author of the pull request is dependabot:

```yml
jobs:
  dependabot:
    runs-on: ubuntu-latest
    if: ${{ github.actor == 'dependabot[bot]' }}
    steps:
```

The first step is to fetch dependabot metadata:

```yml
- name: Dependabot metadata
  id: metadata
  uses: dependabot/fetch-metadata@v1
  with:
    github-token: "${{ secrets.GITHUB_TOKEN }}"
```

Next, add a step that runs on the following conditions based on the metadata: if the dependency name contains your package (replace {OWNER} with your user name) and the version update is a patch version. Merge the pull request if all checks have succeeded using gh merge --auto:

```yml
- name: Enable auto-merge for all patch versions
  if: ${{contains(steps.metadata.outputs.dependency-names, '@{OWNER}/package-recipe') && steps.metadata.outputs.update-type == 'version-update:semver-patch'}}
  run: gh pr merge --auto --merge "$PR_URL"
  env:
    PR_URL: ${{github.event.pull_request.html_url}}
    GITHUB_TOKEN: ${{secrets.GITHUB_TOKEN}}
```

Please note that this workflow will not trigger the publish.yml workflow listening for the push trigger for main. This is because merge is carried out using GITHUB_TOKEN. You can either use a PAT token, as in the last step, or you can move the publish logic to a reusable workflow and call it from this workflow directly.

Now, go back the package-recipe repository and create a new release with a new patch version. Once the new package version is published, head over to Insights | Dependency graph | Dependabot and click on the link in the package.json line. Hit Check for updates to enforce dependabot to now check for updates (see Figure 7.7). Dependabot will create a pull request, trigger the workflow, and the pull request will automatically be merged.

### How it works...

Dependabot can help you to keep your dependencies up to date with less effort. You can use it to automate the update process and to keep up with the latest releases of all your dependencies.

There are many ecosystems supported by this:

> * Bundler
> * Cargo
> * Composer
> * **Dev containers** (including GitHub Codespaces)
> * **Docker**
> * Hex
> * Elm-packages
> * **Git submodules**
> * **GitHub Actions**
> * Go modules
> * Maven and Gradle
> * npm
> * NuGet
> * pip, pipenv, and pip-compile
> * pnpm
> * poetry
> * pub
> * Swift
> * **Terraform**
> * yarn

For a complete list, see the following link: https://docs.github.com/en/code-security/dependabot/dependabot-version-updates/about-dependabot-version-updates.

Dependabot will create pull requests for each version update of each dependency. You can use `@Dependabot` commands on the pull request to interact with dependabot and to tell it certain things, such as ignoring versions or rebasing changes.

The `dependabot.yml` file has many options. You can specify what kind of updates are allowed, customize the commit message, group updates together, ignore certain dependencies, and add reviewers, labels, or assignees. For a complete list of configuration options, see the following link: https://docs.github.com/en/code-security/dependabot/dependabot-version-updates/configuration-options-for-the-dependabot.yml-file. In combination with workflows and the dependabot/fetch metadata actions, this a very powerful tool to automate your supply chain across many repositories and teams. If you look at *Chapters 6* and *7*, we use **Conventional Commits** with **GitVersion** to automate the semantic versioning based on a conventional commit message completely. We can then leverage dependabot to fully automate the update of downstream dependents.

### There’s more...

In our example, we directly build the container and push the deployment to Kubernetes. However, you can also use dependabot to update Kubernetes manifest files by adding an entry to the Docker `package-ecosystem` element of your `dependabot.yml` file for each directory containing a manifest, which references Docker image tags. Kubernetes manifests can be normal Kubernetes deployment files, and **Helm charts** are also supported. For more information about configuring your `dependabot.yml` file for Kubernetes, see the following link: https://docs.github.com/en/code-security/dependabot/dependabot-version-updates/configuration-options-for-the-dependabot.yml-file#docker.

---

## Clean up

Please don’t forget to delete your cluster when you are done with the recipes so that no unnecessary costs will occur. You can use the script destroy-azure.sh in the repo and run it locally or just run the following command in the **Azure Cloud Shell** (https://shell.azure.com):

```sh
az group delete --resource-group AKSCluster --yes
```

Just check that you did not change the name of the resource group when setting everything up.

---

## Summary

Congratulations on making it to the end of the book. I hope the practical, hands-on, focused recipes helped you to build a foundation for automating all kinds of tasks in your day-to-day work and helped increase the productivity in your engineering teams. I tried to include all the aspects of GitHub Actions that are relevant, balancing simplicity and real-world applicability. GitHub is a platform that is evolving very fast, with changes being released multiple times a day. If you consider the partners and actions from the open source community, the GitHub ecosystem is huge and changes all the time. If you have encountered changes during the hands-on labs in this book, please reach out to me on GitHub by creating an issue or submitting a pull request, and I will try to incorporate the changes in the repository. I hope you enjoyed the book, and I hope you will enjoy GitHub Actions as I do; it is the best automation platform I’ve ever used.
