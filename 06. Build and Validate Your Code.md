# Build and Validate Your Code

In this chapter, you will learn how to use GitHub Actions to build and validate code, validate changes in pull requests, and keep your dependencies up to date. You will learn where to store build output and how to optimize your workflow runs with caching.

We will cover the following recipes:

> * Building and testing your code
> * Building different versions using a matrix
> * Informing the user on details of your build and test results
> * Finding security vulnerabilities with CodeQL
> * Creating a release and publishing the package
> * Versioning your packages
> * Generating and using **software bills of materials (SBOMs)**
> * Using caching in workflows

---

## Technical requirements

For this chapter, you will need an up-to-date version of NodeJS and Visual Studio Code. You can also use GitHub Codespaces.

---

## Building and testing your code

In this recipe, we will create a simple **Continuous Integration (CI)** pipeline that builds and validates code and gets integrated into pull request validation. We’ll use this code in subsequent recipes – that’s why we’re using a very simple JavaScript package.

### Getting ready

I think it is best to build a new repository and npm package from scratch. Even if you’re not familiar with JavaScript, this should not be a challenge. You can compare your code or copy it from the following repository: https://github.com/wulfland/package-recipe. If you struggle with this, just clone this repository and work with it.

Create a new public repository called package-recipe. Initialize it with a .gitignore file and a README file and pick Node as the template for the .gitignore file.
Clone your repository locally or open it in Codespaces.
Run the following command:

```sh
npm init
```

Follow the wizard. The name of the package is @<github-user-name>/package-recipe. As the test command, add the following code:

```sh
jest && make-coverage-badge
```

Jest is the test framework we will use to test the application, and with make-coverage-badge, we will later create a badge that we will add to the README file.

You can leave the rest of the properties at their default.

After the wizard has completed, run the following command:

```sh
npm install
```

Install the dependencies:

```sh
npm install --save-dev jest
npm install --save-dev make-coverage-badge
```

Next, let’s add the code. Create a new src/index.js file and add the following lines:

```js
module.exports = function greet () {
  return 'Hello world!'
}
```

We’re creating a simple package that will only return Hello world!.

Add a new __tests__/index.test.js file (with double underscores). Add the following test:

```js
describe('index.js', () => {
  it('greet function returns Hello world!', () => {
    const greet = require('../src/index')
    expect(greet()).toBe('Hello world!')
  })
})
```

This is just a simple test that checks that index.js writes the text as expected to the console.

Open package.json and add the following configuration for Jest:

```json
"jest": {
    "verbose": true,
    "coverageReporters": [
      "json-summary",
      [
        "text",
        {
          "file": "coverage.txt",
          "path": "./coverage"
        }
      ],
      "lcov"
    ],
    "collectCoverage": true,
    "collectCoverageFrom": [
      "./src/**"
    ]
  },
```

This will add multiple report outputs for the code coverage.

Execute the tests:

```sh
npm run test
```

If everything is set up correctly, this will execute the one test and write reports in a coverage folder. It will also generate a badge at coverage/badge.svg.

Commit your files and push them to GitHub.
In the repository, go to Settings and scroll down to Pull Requests. Check Allow auto-merge and Automatically delete head branches.

### How to do it...

Now that we have our package repository ready that we are going to use for the next recipes, let’s start with adding a CI workflow:

Create a new `_github/workflows/ci.yml` file.
Name the workflow CI and trigger it on every pull request to validate the changes. Also, trigger it on every push to the main branch to build a new version that can be released:

```yml
name: CI
on:
  pull_request:
  push:
    branches:
      - main
```

Add a build job that runs on ubuntu-latest and checks out of the repository:

```yml
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
```

Configure the workflow runner to target a specific NodeJS version. We can use a wildcard for minor versions and have the action use the latest version available:

```yml
- uses: actions/setup-node@v4
  with:
    node-version: "21.x"
    check-latest: true
```

Build and test the code:

```yml
- name: Install dependencies
  run: npm install
- name: Run tests
  run: npm test
```

Commit and push the workflow to the main branch. This should already trigger the workflow because of the push trigger, and the build and test should succeed.
To test the validation, create a new branch:

```sh
git switch -c fail-pr
```

Modify index.js to something that will fail the test (that is, console.log('Hello Mars!');). Add and commit the changes and create a pull request:

```sh
git add index.js
git commit
git push -u origin fail-pr
gh pr create --fill
```

The pull request will trigger the workflow, and it will fail because the npm run test command will return a nonzero value.

### How it works...

Let’s understand how the validation works.

Checkout
The first thing necessary for CI is checking out of your repository with the checkout action (https://github.com/actions/checkout). The action has many parameters. For example, you can set the depth of the git history you pull down to the runner. The default is 1, and that will only download the HEAD branch. In the recipe to generate version numbers from git, we’ll set that to 0 to download all branches and tags:

```yml
steps:
  - uses: actions/checkout@v4
    with:
      fetch-depth:0 # Default: 1
```

Other options are lfs to determine if Git Large File Storage (LFS) files should be downloaded or not (default is false) or submodules:

```yml
steps:
  - uses: actions/checkout@v4
    with:
      lfs: true # Default: false
      submodules: true # Default: false
```

For large monorepos, you can also perform a sparse checkout and only get data for a specific area of the repo. This example only checks out the .github, src, and __tests__ folders:

```yml
steps:
  - uses: actions/checkout@v4
    with:
      sparse-checkout: |
        .github
        src
        __tests__
```

This can reduce the time and storage needed by the workflow tremendously.

#### Setup environment

There are different setup actions for the following programming languages:

> * Node
> * Python
> * Java
> * Go
> * .NET
> * Ruby
> * Elixir
> * Haskell

In our case, we use `setup-node` (https://github.com/actions/setup-node). Setup actions ensure the correct binaries and environment variables are set in the build process. All the actions take some form of version parameter:

```yml
- uses: actions/setup-node@v4
  with:
    node-version: 21
```

Wildcards are supported as well as aliases. Examples are `21.x`, `21.5.0`, `>=21.5.0`, `lts/Hydrogen`, `21-nightly`, `latest`. If you use wildcards, then you can set `check-latest: true` to check for the latest version available.

Most checkout actions also support different registries to download dependencies. For node, the parameter is `registry-url`, which will use the URL provided and a token from `env.NODE_AUTH_TOKEN` to connect to the specific registry.

Checkout actions normally also cache dependencies. In many cases, it is more efficient to use the corresponding setup action than implementing caching yourself (we have a recipe for that later in this chapter).

### There’s more...

A validation workflow is best combined with branch protection and rulesets – and you can add a linter to the mix to further increase the quality.

#### super-linter

In Chapter 2, *Authoring and Debugging Workflows*, we used a linter to validate and annotate our workflows in pull requests. The same can be done for code. There is a GitHub action called `super-linter` (see https://github.com/super-linter/super-linter) that basically combines all available linters in one action. You can use it to lint your code like this:

```yml
permissions:
  contents: read
  packages: read
  # To report GitHub Actions status checks
  statuses: write
steps:
  - name: Checkout code
    uses: actions/checkout@v4
    with:
      # super-linter needs the full git history to get the
      # list of files that changed across commits
      fetch-depth: 0
  - name: Super-linter
    uses: super-linter/super-linter@v5.7.2
    env:
      DEFAULT_BRANCH: main
      # To report GitHub Actions status checks
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

The image of `super-linter` is quite huge and can impact the performance of your workflows. If you don’t need all languages, then you can also use the slim version:

```sh
super-linter/super-linter/slim@[VERSION]
```

It excludes linters for `rust`, `dotenv`, `armttk`, `pwsh`, and `c#`, and the image size is much smaller. In `v5`, this will reduce the size from 7.35 GB to 4.88 GB in `slim-v5`, and this will reduce the time to just pull down the image from about 2 minutes to about 1 minute.

Branch protection

In Chapter 2, *Authoring and Debugging Workflows*, I also introduced you to branch protection. You can protect one or multiple branches in a repository with rules and enforce that commits are merged with a pull request and certain checks are successful. In addition to manual reviews, you can request status checks to be successful (see *Figure 6.1*):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_1.jpg)<br>
Figure 6.1 – Adding GitHub Action workflow jobs as status checks for a protected branch

Status checks can be a single job of a workflow – or any integration that uses the status API to report status. You can enable a policy for main in your repository for the next recipes and set the status check policy to the jobs of the workflow. See https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/managing-protected-branches/about-protected-branches for more information on protected branches.

Rulesets
Rulesets are the more powerful successor of branch protection. They have the same power as protected branches. You can also define status checks the same way you do in protected branches (see *Figure 6.2*):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_2.jpg)<br>
Figure 6.2 – Adding GitHub Action workflow jobs as status checks in a ruleset

Most of the rules that can be used in rulesets are similar to branch protection rules and can be used in combination without changing existing ones.

Rulesets are more advanced and have the following advantages over protection rules:

Rulesets can be defined at the organization level and can target multiple repositories.
Rules can be layered by applying multiple rulesets at the same time.
Rulesets have a status that allows you to activate and deactivate rulesets in a repository without the need to delete them.
You only need read access to a repository to view all active rulesets. This makes it much more transparent to contributors which rules apply.
There are some additional rules that are not available in protection rules, such as rules to control commit messages or the author’s email address.
You can learn more about rulesets here: https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/managing-rulesets/about-rulesets.

Building different versions using a matrix
In this recipe, we are going to build and test our software for different versions, in our case, of the NodeJS environment.

### Getting ready

Make sure you have cloned the repository from the previous recipe. Create a new branch to modify the workflow:

```sh
git switch -c build-matrix
```

Open the .github/workflows/ci.yml file in an editor.

### How to do it...

Add the following code to the workflow file:

```yml
strategy:
  matrix:
    node-version: ["21.x", "20.x"]
```

Adjust the versions if needed.

In the actions/setup-node action, set the node version to the corresponding value from the matrix context:

```yml
- uses: actions/setup-node@v4
  with:
    node-version: ${{ matrix.node-version }}
    check-latest: true
```

Commit and push your changes and create a pull request:

```sh
git add .
git commit
git push -u origin build-matrix
gh pr create --fill
```

Check the output of the workflow. It will run a separate job for each entry in the matrix array (see Figure 6.3):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_3.jpg)<br>
Figure 6.3 – The matrix runs a different job for each entry

Wait until the workflow has completed. Merge your pull request and clean up your repository:

```sh
gh pr merge -m
```

### How it works...

The matrix is a convenient way to use the same workflow jobs with different combinations. It can contain one or multiple arrays that can contain many values. The matrix will run all combinations of all values in all arrays. You can think of the matrix as nested for loops. A good example is running and testing different versions on different platforms:

```yml
jobs:
  example_matrix:
    strategy:
      matrix:
        os: [ubuntu-22.04, ubuntu-20.04]
        version: [10, 12, 14]
    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ matrix.version }}
```

This way, you can reuse the same workflow logic to test many different combinations of values at the same time.

### There’s more...

The matrix has some additional features. You can set fail-fast to indicate if it will cancel the workflow if one job in the matrix fails or if it should continue. You can define the number of parallel jobs with max-parallel, and you can include and exclude values for certain elements. Here is a more complex example:

```yml
jobs:
  test:
    runs-on: ubuntu-latest
    continue-on-error: ${{ matrix.experimental }}
    strategy:
      fail-fast: true
      max-parallel: 2
      matrix:
        version: [5, 6, 7, 8]
        experimental: [false]
        include:
          - version: 9
            experimental: true
```

To learn more about the matrix strategy, see https://docs.github.com/en/actions/using-jobs/using-a-matrix-for-your-jobs.

Informing the user on details of your build and test results
In this recipe, we are going to decorate pull requests and workflow summaries with details of our test results. We’ll also add badges to the README file to indicate the quality of a branch or release.

### Getting ready

Create a new branch to do the modification:

```sh
git switch -c add-badges
```

### How to do it...

You can download badges for workflows using the following URL:

```sh
https://github.com/OWNER/REPO/actions/workflows/FILE.yml/badge.svg
```

You can also filter by branch or event by adding query parameters (for example, ?branch=main or ?event=push). We want a badge for the main branch, so add the following image to the markdown of your README:

```sh
![main](https://github.com/OWNER/package-recipe/actions/workflows/ci.yml/badge.svg?branch=main)
```

The badge will use the name in the workflow file and look like Figure 6.4 in the preview:

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_4.jpg)<br>
Figure 6.4 – Badge for the CI workflow

But we want to go one step further and add a code coverage badge to the README, annotate pull requests with the code coverage output, and add a summary to the workflow.

To decorate the pull requests, the workflow needs write permissions. And, as we build multiple versions with the matrix, we have to pick one that we use for the creation of the badge. Add the following code to the build job:

```yml
jobs:
  build:
    permissions:
        pull-requests: write
    env:
      MAIN_VERSION: "21.x"
```

In the workflow file, add the following code right after run: npm test:

```yml
- name: Prepare coverage report in markdown
  uses: fingerprintjs/action-coverage-report-md@v1.0.6
  id: coverage
  with:
    textReportPath: coverage/coverage.txt
```

This uses the fingerprintjs/action-coverage-report-md action to create a report in markdown that we’ll write to the job summary and the pull request.

Next, we use the marocchino/sticky-pull-request-comment action to write the markdown report to the pull request:

```yml
- name: Add coverage comment to the PR
  uses: marocchino/sticky-pull-request-comment@v2.8.0
  with:
    message: ${{ steps.coverage.outputs.markdownReport }}
```

Also, write the output to $GITHUB_STEP_SUMMARY. As we run the job in a matrix, add a heading indicating the version number:

```yml
- name: Add coverage report to the job summary
  run: |
    echo "## Code Coverage v${{ matrix.node-version }}" >> "$GITHUB_STEP_SUMMARY"
    echo "${{ steps.coverage.outputs.markdownReport }}" >> "$GITHUB_STEP_SUMMARY"
```

Commit and push your changes and create a pull request:

```sh
git add .
git commit
git push -u origin add-badges
gh pr create –fill
```

This will trigger the workflow with the pull request trigger, and you can inspect in the workflow run the job summary, which should look like Figure 6.5:

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_05.jpg)<br>
Figure 6.5 – Displaying code coverage results in the workflow summary

The summary is also added as a comment to the pull request (see Figure 6.6):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_06.jpg)<br>
Figure 6.6 – Adding code coverage results as a pull request comment

The badge for code coverage is automatically created by the npm package during test. But in order to add the badge (that is, to the README), we need a place to host it. We’ll use GitHub Pages for this.
Add the following code to the end of the build job to upload the artifacts to the workflow. Note that this is not the normal actions/upload-artifact action – it is a special action for GitHub Pages:

```yml
- name: Upload page artifacts
  if: ${{ matrix.node-version == env.MAIN_VERSION }}
  uses: actions/upload-pages-artifact@v3
  with:
    path: coverage
```

As we can only upload one artifact with the same name, we only run this step if the node version of the matrix is our main version.

Add a new deploy job after build that only runs on pushes to main and depends on the build job:

```yml
deploy:
  if: ${{ github.ref == 'refs/heads/main' }}
  needs: build
  runs-on: ubuntu-latest
```

Create a concurrency group called pages so that we only deploy one version at a time to the pages environment. But don’t cancel deployments that are in progress to deploy all versions:

```yml
concurrency:
  group: "pages"
  cancel-in-progress: false
```

The job needs the following permissions:

```yml
permissions:
  contents: read
  pages: write
  id-token: write
```

The job deploys to the github-pages environment and uses the URL from the actions/deploy-pages action to display it in the workflow. The URL will point to the root of the package. As the HTML report with our index.html file is in the lcov-report folder, we add this to the URL:

```yml
environment:
  name: github-pages
  url: "${{ steps.deployment.outputs.page_url }}lcov-report"
```

The job has only two simple steps – configure-pages and deploy-pages:

```yml
steps:
  - name: Setup Pages
    uses: actions/configure-pages@v4
  - name: Deploy to GitHub Pages
    id: deployment
    uses: actions/deploy-pages@v4
```

Commit and push your changes and merge the pull request after the workflow has completed:

```sh
git add .
git commit
git push
gh merge -m
```

After the pull request is merged, a new workflow run will be triggered by the push to main. Once it is completed, you can see the URL to the website that has the report (see Figure 6.7):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_07.jpg)<br>
Figure 6.7 – Inspecting the Pages website

The website created by GitHub contains the badge in the root of the directory. The URL looks like this: https://{OWNER}.github.io/package-recipe/badge.svg. The URL of the badge in markdown would look like this:

```sh
[![Coverage](https://wulfland.github.io/package-recipe/badge.svg)]
```

But as we want to be directed to our lcov-report folder in the website when clicking on the badge, we’ll add a link around the image. Add the following markdown to your README (replace wulfland with your GitHub username):

```sh
[![Coverage](https://wulfland.github.io/package-recipe/badge.svg)](https://wulfland.github.io/package-recipe/lcov-report)
```

The badge will look like Figure 6.8, and when you click on it, you’ll be redirected to the coverage report:

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_08.jpg)<br>
Figure 6.8 – Adding a badge for test coverage

### How it works...

Let’s understand how the code works.

Adding a workflow status badge
You can display a status badge for workflows in your repository to indicate the status of the workflows.

The URL of the badge is the following, and it will use the name of the workflow and show the status of the last workflow run:

```log
https://github.com/OWNER/REPOSITORY/actions/workflows/WORKFLOW-FILE/badge.svg
```

Typically, you only want to display the status for a specific branch or event. You can do so by providing the corresponding parameters (that is, ?branch=main or ?event=push). This way, you can display multiple badges for different versions of your software. See https://docs.github.com/en/actions/monitoring-and-troubleshooting-workflows/adding-a-workflow-status-badge for more information.

GitHub Pages
GitHub Pages is a static site hosting service from GitHub that takes static files from a repository and publishes them as a website. The site is hosted on GitHub’s github.io domain, or you can use your own custom domain.

Unless you’re using a custom domain, project sites are available at the following URLs:

http(s)://<username>.github.io/<repository> or
http(s)://<organization>.github.io/<repository>.

Pages can be deployed directly from a branch and, optionally, prepossessed with Jekyll (https://github.com/jekyll/jekyll). This way, you can easily render markdown files as a website – for example, to host a blog.

You can find an example under https://wulfland.github.io/AccelerateDevOps/ that renders the content of the https://github.com/wulfland/AccelerateDevOps/tree/main/docs folder.

In addition to deploying from a branch, you can also deploy pages using your own workflows. This is what we did in this recipe. The feature is still in beta at the time of writing – but in my opinion, it can already be used in production.

See https://docs.github.com/en/pages/getting-started-with-github-pages/about-github-pages to learn more about GitHub Pages.

Concurrency groups
By default, GitHub Actions allows multiple jobs within the same workflow and multiple workflow runs within the same repository to run concurrently – meaning that multiple steps can run at the same time.

GitHub Actions also allows you to control the concurrency of workflow runs so that you can ensure that only one run, one job, or one step runs at a time in a specific context. This can be useful for controlling situations when running multiple steps at the same time could cause conflicts or consume more action minutes than expected.

Concurrency groups can have a static name, like we did in our recipe. But you can also use context expressions to group certain contexts – such as branches – together in one group:

```yml
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true
```

The cancel-in-progress parameter can be used to cancel a job if a newer version is available and run that instead. This can help save resources. If it is set to false, the workflow will wait until the previous version has completed and then run the next job in the concurrency queue. This way, only one job at a time gets executed for a given group.

You can learn more about concurrency groups here: https://docs.github.com/en/actions/using-jobs/using-concurrency.

### There’s more...

Validating code automatically and bringing detailed information to where it is valuable for the developers is very important. In addition to test results, code coverage, and linters, you can also integrate solutions such as SonarQube or SonarCloud. They provide a great GitHub integration and are free for open source. Just log in with your GitHub credentials, and you can configure a new project. The project allows you to create additional badges that you can add to your README (see Figure 6.9):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_11.jpg)<br>
Figure 6.9 – Using SonarCloud badges in your GitHub README

Sonar badges provide a great integration into your pull request and can be used as an additional status check in rulesets and branch protection rules. The quality gates are reported in the pull request (see Figure 6.10):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_12.jpg)<br>
Figure 6.10 – Pull request integration of SonarCloud quality gates

To learn more about GitHub integration for SonarCloud, see the documentation at https://docs.sonarsource.com/sonarcloud/getting-started/github/.

---

## Finding security vulnerabilities with CodeQL

This is a short recipe that we will use to add a CodeQL analysis to our existing CI build. CodeQL is the code analysis engine from GitHub, and it is free for public repositories.

### Getting ready

Create a new branch in the package-recipe repository:

```sh
git switch -c add-codeql
```

### How to do it...

Open the .github/workflows/ci.yml file and grant the build job permissions to write security events:

```yml
build:
  permissions:
    pull-requests: write
    security-events: write
```

Add an init action (github/codeql-action/init) to the job. For languages that must be compiled, this has to go before the build process. As JavaScript is a static language, you can add it to the end of the job. Set the language to javascript-typescript and select the security-and-quality query suite:

```yml
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: 'javascript-typescript'
          queries: security-and-quality
```

Performing the actual analysis is executed after compilation. Just add the following code to the end of the job:

```yml
      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3
        with:
          category: "/language:javascript-typescript"
```

Commit your code, create a pull request, and merge the changes when all the checks have passed:

```sh
git add .
git commit
gh pr create --fill
gh pr merge -m --auto
```

### How it works...

CodeQL is the code analysis engine from GitHub to automate security and quality checks. It is free in public repositories, and it is available for enterprises that purchase the GitHub Advanced Security license.

You can analyze the following languages:

> * C/C++
> * C#
> * Go
> * Java
> * Kotlin (in beta at the time of writing)
> * JavaScript/TypeScript
> * Python
> * Ruby
> * Swift (in beta at the time of writing)

There are three ways to analyze your code:

> * **Default**: The default setup for CodeQL will automatically detect the languages in your repository and pick the supported ones to analyze. It will apply the default query suites and triggers for the scans. In the repository, under **Settings | Code security and analysis**, you can select **Default** if the languages in your repository are supported by that feature (see *Figure 6.11*):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_13.jpg)<br>
Figure 6.11 – Configuring code scanning with Default or Advanced mode

> * **Advanced**: Use a custom workflow and add the CodeQL analysis as we did in the recipe. If you click on **Advanced** in **Settings** (*Figure 6.11*), this will generate a customizable workflow template for you. It will use a matrix strategy with `fail-fast: false` to analyze all languages detected in your repository.
> 
> * **CLI**: Run the CodeQL CLI directly in an external CI system and upload the results to GitHub.

The results of the analysis of all tools can be accessed under **Security | Code scanning** (see *Figure 6.12*):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_14.jpg)<br>
Figure 6.12 – Viewing code analysis results in a repository

You can access the status of all tools that report results. Note that in our repository, the analysis also analyses code generated by our test packages.

To learn more about CodeQL, visit https://docs.github.com/en/code-security/code-scanning/introduction-to-code-scanning/about-code-scanning-with-codeql.

### There’s more...

GitHub supports all kinds of other tools – among others, **Checkmarx, Snyk, Microsoft Defender for DevOps**, and **ESLint**. It supports many commercial ones but also many that are free or open source.

If you click on **Explore workflows** in your repository under **Settings | Code security and analysis** (see Figure 6.13), then you will be redirected to a new workflow page filtered by the `security` category and `code scanning` query (`https://github.com/OWNER/REPO/actions/new?category=security&query=code+scanning`):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_15.jpg)<br>
Figure 6.13 – Adding third-party scanning tools to your repository

You can explore all partners that have published a template workflow to the marketplace.

If you have other tools, you can still integrate them as long as they support Static Analysis Results Interchange Format (SARIF; see https://sarifweb.azurewebsites.net/) – the approved Organization for the Advancement of Structured Information Standards (OASIS) standard for static code analysis – as an output format.

To give you an example, you could use Checkov, a static code analysis tool for infrastructure as code (IaC) supporting Terraform, Terraform plan, CloudFormation, AWS Serverless Application Model (SAM), Kubernetes, Helm charts, Kustomize, Dockerfiles, Serverless, Bicep, OpenAPI or ARM templates. Use the action bridgecrewio/checkov-action action to run your analysis and then upload the results to GitHub:

```yml
- name: Checkov GitHub Action
  uses: bridgecrewio/checkov-action@v12
  with:
    output_format: sarif
- name: Upload SARIF file
  uses: github/codeql-action/upload-sarif@v3
  with:
    sarif_file: results.sarif
  if: always()
```

This way, you can easily integrate all code scanning tools available on the market, as long as they support SARIF.

---

## Creating a release and publishing the package

In this recipe, we are going to create a workflow that will publish our package whenever a release is created.

### Getting ready

Create a new branch:

```sh
git switch -c add-release-workflow
```
### How to do it...

Create a new .github/workflows/release.yml workflow file. Name the workflow Release and trigger it on the creation of GitHub releases:

```yml
name: Release
on:
  release:
    types: [created]
```

Add a publish job and give it read permission for the repository and write for packages:

```yml
jobs:
  publish:
    runs-on: ubuntu-latest
    permissions:
      packages: write
      contents: read
```

Check out the code and configure the NodeJS environment with the correct version. Also, set the registry to use GitHub:

```yml
steps:
  - uses: actions/checkout@v4
  - uses: actions/setup-node@v4
    with:
      node-version: 21.x
      registry-url: https://npm.pkg.github.com/
```

Build and test the application and publish it to the registry using a GitHub token:

```yml
- name: Install dependencies
  run: npm install
- name: Run tests
  run: npm test
- run: npm publish
  env:
    NODE_AUTH_TOKEN: ${{secrets.GITHUB_TOKEN}}
```

Commit your changes, create a pull request, and merge the changes once the checks have passed:

```sh
git add .
git commit
gh pr create --fill
gh pr merge -m --auto
```

Once your pull request has been merged, go to Releases on the Code tab of your repository and click Draft a new Release.
Click Choose a tag, enter v1.0.0, and click Create new tag. Instead of adding the body of the release in markdown, just click Generate release notes (see Figure 6.14):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_16.jpg)<br>
Figure 6.14 – Drafting a new release for a tag and generating release notes

This will generate details for your release from your pull requests. Click Publish release to create the release. The release should look like Figure 6.15:

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_17.jpg)<br>
Figure 6.15 – Details of a GitHub release

It should also contain the source code as .zip and .tar archives per default (see Figure 6.16):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_18.jpg)<br>
Figure 6.16 – Assets of a release contain the source code as .zip and .tar archives

The creation of the release will trigger the workflow, and it will publish your package with version 1.0.0 to your repository (note that this comes from your package.json file and not the tag!).
The package looks like Figure 6.17:

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_19.jpg)<br>
Figure 6.17 – The package in the repository

It contains installation instructions, information on your repository, and the README with your badges.

### How it works...

Now, we’ll see how it works.

Semantic versioning
Packages are typically created using semantic versioning, a formal convention for specifying version numbers for software. It consists of different parts with different meanings. Examples of semantic version numbers are 1.0.0 or 1.5.99-beta. The format is as follows:

```log
<major>.<minor>.<patch>-<pre>
```

Major version: A numeric identifier that gets increased if the version is not backward compatible and has breaking changes. An update to a new major version must be handled with caution! A major version of zero is for the initial development.
Minor version: A numeric identifier that gets increased if new features are added, but the version is backward compatible with the previous version and can be updated without breaking anything if you need the new functionality.
Patch: A numeric identifier that gets increased if you release bug fixes that are backward compatible. New patches should always be installed.
Pre-version: A text identifier that is appended using a hyphen. The identifier must only use ASCII alphanumeric characters and hyphens ([0-9A-Za-z-]). The longer the text, the smaller the pre-version (meaning -alpha < -beta < -rc). A pre-release version is always smaller than a normal version (1.0.0-alpha < 1.0.0).
See https://semver.org/ for the complete specification.

In our case, the semantic version for the package was set in the package.json file. In the next recipe, we will use the release process to automatically set the version number of the package to the release so that you do not have to do this manually.

Releases
You can create a release to package software, release notes, and binary files for other people to download.

GitHub releases are deployable software versions you can package and make available for a wider audience to download and use. They can contain release notes and other binary files to download.

Releases are based on Git tags, which mark a specific point in your repository’s history.

In the next recipes, we will use GitHub Releases together with tags to automatically version our package and to attach an SBOM in an automated way. To learn more about GitHub Releases, see https://docs.github.com/en/repositories/releasing-projects-on-github.

### There’s more...

Releasing and versioning of software depends a lot on your workflow – especially how you work with git branches and tags. In our example, I assume that you start a release process by directly creating a release. You could also use the push of a tag:

```yml
on:
  push:
    tags:
      - v*.**
```

The workflow would be triggered by any push of a tag that starts with v, and you could use it to automatically create a release:

```sh
gh release create ${{ github.ref_name }} --generate-notes
```
You could also do this on pushes to a release branch:

```yml
on:
  push:
    branches:
      - release/*
```

Versioning your packages
If you now created a new release, the workflow would fail as it would try to publish version 1.0.0 again to the package registry. You would manually have to set the version number in the package.json file. In this recipe, we will use GitVersion to automate this process.

### Getting ready

Switch to a new branch:

```sh
git switch -c add-gitversion
```

### How to do it...

For GitVersion to automatically determine the version of your git workflow, you have to download all references and not just the HEAD branch. We do this by adding the fetch-depth parameter to the checkout action and setting it to 0:

```yml
- uses: actions/checkout@v4
  with:
    fetch-depth: 0
```

Set up GitVersion in a specific version:

```yml
- name: Install GitVersion
  uses: gittools/actions/gitversion/setup@v0.10.2
  with:
    versionSpec: '5.x'
```

Execute GitVersion to determine the version number:

```yml
- name: Determine Version
  uses: gittools/actions/gitversion/execute@v0.10.2
```

Change the version of the npm package:

```yml
- name: 'Change NPM version'
  uses: reedyuk/npm-version@1.2.2
  with:
    version: $GITVERSION_SEMVER
```

Commit your changes, create a pull request, and merge it when all checks have passed:

```sh
git add .
git commit -m '(build): Add GitVersion to automatically set version'
gh pr create --fill
gh pr merge -m --auto
gh pr checks
```

Wait until all checks have passed. Then, create the release:

```sh
gh release create v1.0.1 --generate-notes
```

You will have a new release like *Figure 6.18* – this time created from the CLI:

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_20.jpg)<br>
Figure 6.18 – Creating a release from the CLI that will trigger the workflow to publish a new package with the same version as the release

The release will trigger the workflow, and a new package with version 1.0.1 will be released.

### How it works...

GitVersion (see https://gitversion.net/docs/) is a tool that automatically generates a semantic version number based on your Git history. GitVersion runs with a default configuration that works with GitHub flow (https://docs.github.com/en/get-started/using-github/github-flow) and Git flow (https://nvie.com/posts/a-successful-git-branching-model/). You can run GitVersion init to launch a wizard that guides you through creating a config file (GitVersion.yml). In our example, we use the Continuous Delivery mode – meaning we explicitly create a version using a tag. But there are also other modes such as Continuous Deployment mode (creating a version from every commit to specific branches) or Mainline mode.

The gittools/actions/gitversion/execute action will execute GitVersion and save the result in the $GITVERSION_SEMVER environment variable. You can also access individual parts of the version and configuration using the output of the action:

```yml
  - name: Determine Version
    id: gitversion
    uses: gittools/actions/gitversion/execute@v0
  - name: Display GitVersion outputs (step output)
    run: |
      echo "Major: ${{ steps.gitversion.outputs.major }}"
      echo "Minor: ${{ steps.gitversion.outputs.minor }}"
      echo "Patch: ${{ steps.gitversion.outputs.patch }}"
```

### There’s more...

You can also use Conventional Commits (see https://www.conventionalcommits.org) to automatically determine semantic versions out of commit messages. Conventional Commits is a specification that provides a set of rules for creating an explicit commit history by describing features, fixes, and breaking changes made in commit messages. You can use Conventional Commits to create release notes – and you can use it with GitVersion to automatically determine if a new version is a patch, minor, or major number. This is done in the GitVersion.yml configuration:

```yml
mode: Mainline
major-version-bump-message: "^(build|chore|ci|docs|feat|fix|perf|refactor|revert|style|test)(\\([\\w\\s-]*\\))?(!:|:.*\\n\\n((.+\\n)+\\n)?BREAKING CHANGE:\\s.+)"
minor-version-bump-message: "^(feat)(\\([\\w\\s-]*\\))?:"
patch-version-bump-message: "^(build|chore|ci|docs|fix|perf|refactor|revert|style|test)(\\([\\w\\s-]*\\))?:"
```

In the CI build, you can then add a job that determines the version out of the Conventional Commit messages and creates a new release:

```yml
publish:
  if: ${{ github.ref == 'refs/heads/main' }}
  needs: build
  runs-on: ubuntu-latest
  permissions:
    contents: write
  steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
    - name: Install GitVersion
      uses: gittools/actions/gitversion/setup@v0.10.2
      with:
        versionSpec: '5.x'
    - name: Determine Version
      uses: gittools/actions/gitversion/execute@v0.10.2
      with:
        useConfigFile: true
    - name: Create a new release
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        gh release create ${{ env.GITVERSION_SEMVER }} --generate-notes
```

The two workflows together will then completely automate the creation of new versions after every merge to main.

Generating and using SBOMs
An SBOM (see https://www.cisa.gov/sbom) declares the nested inventory of components that make up the software. The United States government is required to obtain an SBOM for any product they purchase by the Cyber Supply Chain Management and Transparency Act of 2014.

You can manually export an SBOM in GitHub under Insights | Dependency graph | Export SBOM (see Figure 6.19):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_21.jpg)<br>
Figure 6.19 – Manually exporting an SBOM in a repository

The SBOM is a JSON file following the Software Package Data Exchange (SPDX) standard.

In this recipe, we will automate the process of generating an SBOM from the current dependencies of the repository and attach it to the release as an additional attachment.

### Getting ready

Switch to a new branch:

```sh
git switch -c upload-sbom
```

### How to do it...

Edit the .github/workflows/release.yml file. Modify the permission for the publish job to allow write access to permissions:

```yml
jobs:
  publish:
    runs-on: ubuntu-latest
    permissions:
      packages: write
      contents: write
```

After the Publish package step, add the following step, which calls the API using the GitHub CLI and downloads the SBOM:

```yml
- name: Generate SBoM
  env:
    GH_TOKEN: ${{ github.token }}
  run: |
    gh api \
      -H "Accept: application/vnd.github+json" \
      -H "X-GitHub-Api-Version: 2022-11-28" \
      /repos/wulfland/package-recipe/dependency-graph/sbom > sbom.json
```

Add the svenstaro/upload-release-action action and upload the SBOM as an attachment to the release:

```yml
- name: Upload SBoM to release
  uses: svenstaro/upload-release-action@v2
  with:
    file: sbom.json
    asset_name: SBoM
    tag: ${{ github.ref }}
    overwrite: true
```

Commit the workflow, create a pull request, and merge it back once the checks have passed:

```sh
git add .
git commit
gh pr create --fill
gh pr merge -m --auto
gh pr checks
```

Wait until all checks have passed. Then, create a release:

```sh
gh release create v1.0.5 --generate-notes
```

The workflow will create a release and attach the SBOM as an asset (see Figure 6.20):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_22.jpg)<br>
Figure 6.20 – Automatically attached SBOM as an asset in the release

You can download and inspect the JSON file from the release.

### How it works...

There is always the need to store output – sometimes binary and sometimes text files, as in this case – when releasing software.

You can upload artifacts to the GitHub workflow using the https://github.com/actions/upload-artifact action:

```yml
- uses: actions/upload-artifact@v4
  with:
    name: my-artifact
    path: path/**/[abc]rtifac?/*
```

We did this with the test badges to publish them to GitHub Pages. You can then download the artifacts from the workflow summary page or in subsequent jobs using the https://github.com/actions/download-artifact action:

```yml
- uses: actions/download-artifact@v4
  with:
    name: my-artifact
```

But for end users, it is more convenient to store everything in a release. This way, you bundle all build output with an exact version of your source code. You can manage release assets using the API (see https://docs.github.com/en/rest/releases/assets):

```sh
gh api \
  --method POST \
  -H "Accept: application/vnd.github+json" \
  -H "X-GitHub-Api-Version: 2022-11-28" \
  --hostname HOSTNAME \
  /repos/OWNER/REPO/releases/ID/assets?name=example.zip \
  -f '@example.zip'
```

But there are many actions available that help with that. We use the svenstaro/upload-release-action action – but there are many others. For example, GitReleaseManager from GitTools (see https://github.com/GitTools/actions/blob/main/docs/examples/github/gitreleasemanager/index.md) has an entire suite of actions to interact with releases.

### There’s more...

There are different common formats for SBOM:

SPDX: SPDX is an open standard for SBOM with origins in the Linux Foundation. Its origin was license compliance, but it also contains copyrights, security references, and other metadata. SPDX was recently approved as an ISO/IEC standard (ISO/IEC 5962:2021), and it fulfills the National Telecommunications and Information Administration’s (NTIA’s) The Minimum Elements For a Software Bill of Materials.
CycloneDX (CDX): CDX is a lightweight open source format with origins in the Open Worldwide Application Security Project (OWASP) community. It is optimized for integrating SBOM generation into a release pipeline.
Software Identification (SWID) tags: SWID is an ISO/IEC industry standard (ISO/IEC 19770-2) used by various commercial software publishers. It supports automation of software inventory, assessment of software vulnerabilities on machines, detection of missing patches, targeting of configuration checklist assessments, software integrity checking, installation and execution whitelists/blacklists, and other security and operational use cases. It is a good format for doing the inventory of the software installed on your build machines.
There are different tools and use cases for each format. SPDX is used by GitHub, FOSSology, and syft. You can use the Anchore SBOM Action (see https://github.com/marketplace/actions/anchore-sbom-action) to generate an SPDX SBOM for a Docker or Open Container Initiative (OCI) container:

```yml
      - name: Anchore SBOM Action
        uses: anchore/sbom-action@v0.6.0
        with:
          path: .
          image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          registry-username: ${{ github.actor }}
          registry-password: ${{ secrets.GITHUB_TOKEN }}
```

The SBOM is being uploaded as a workflow artifact.

CDX (https://cyclonedx.org/) is more focused on application security. There are versions for NodeJS, .NET, Python, PHP, and Go in the marketplace – but many more languages are supported using the CLI or other package managers (Java, Maven, Conan, and many more). The usage is simple. Here is an example of the action for .NET:

```yml
- name: CycloneDX .NET Generate SBOM
  uses: CycloneDX/gh-dotnet-generate-sbom@v1.0.1
  with:
    path: ./CycloneDX.sln
    github-bearer-token: ${{ secrets.GITHUB_TOKEN }}
```

The SBOM does not get uploaded automatically unlike the Anchore action – you would have to do that manually:

```yml
- name: Upload a Build Artifact
  uses: actions/upload-artifact@v2.3.1
  with:
    path: bom.xml
```

CDX is also used in OWASP Dependency-Track (see https://github.com/DependencyTrack/dependency-track) – a component analysis platform that you can run as a container or in Kubernetes. You can upload the SBOM directly into your Dependency-Track instance:

```yml
- uses: DependencyTrack/gh-upload-sbom@v1.0.0
  with:
    serverhostname: 'your-instance.org'
    apikey: ${{ secrets.DEPENDENCYTRACK_APIKEY }}
    projectname: 'Your Project Name'
    projectversion: 'main'
```

SWID tags are more used in software asset management (SAM) solutions such as Snow (https://www.snowsoftware.com/), Microsoft System Center, or ServiceNow IT Operations Management (ITOM). CDX and SPDX can use SWID tags if they are present.

If you want to learn more about SBOM, see https://www.ntia.gov/sbom.

Using caching in workflows
In this recipe, we will use caching to optimize the speed of workflows.

### Getting ready

Switch to a new branch:

```sh
git switch -c cache-npm-packages
```

### How to do it...

Edit the .github/workflows/ci.yml file. After the setup-node action, add the following script to get the npm cache directory for the correct npm version and store it as an output variable:

```yml
- name: Get npm cache directory
  id: npm-cache-dir
  run: echo "dir=$(npm config get cache)" >> "${GITHUB_OUTPUT}"
```

Add the actual cache step right after that. Also, give it a name and create a key from the hash of the package-lock.json file:

```yml
- uses: actions/cache@v3
  id: npm-cache
  with:
    path: ${{ steps.npm-cache-dir.outputs.dir }}
    key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
    restore-keys: |
      ${{ runner.os }}-node-
```

The next step will just list the dependencies if they are added to the cache:

```yml
- name: List the state of node modules
  if: ${{ steps.npm-cache.outputs.cache-hit != 'true' }}
  continue-on-error: true
  run: npm list
```

Commit your changes and create a pull request:

```sh
git add.
git commit
gh pr create --fill
```

Open the CI workflow run in your pull request and inspect the output of the steps we added. Rerun both jobs and note how the action restores the packages from the cache and how cache-hit prevents the next step from executing (see Figure 6.21):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_211.jpg)<br>
Figure 6.21 – The cache is successfully restored and cache-hit is true

Merge your pull request:

```sh
gh pr merge -s --auto
```

### How it works...

It is important to only use the cache if you have performance problems. If you use the setup actions, you probably not going to see a big improvement. But it is important to know how caching works to have the tool available if you need it.

The cache action (https://github.com/actions/cache) stores information on GitHub-owned cloud storage and retrieves it in subsequent runs from that.

Let’s assume you have a long-running operation – such as calculating prime numbers – and you use the output in a subsequent step. (I just use a sleep here to simulate a long-running task):

```yml
- name: Generate Prime Numbers
  run: |
    sleep 60
    echo "1 2 3..." > primes
- name: Use Prime Numbers
  run: cat primes
```

You can now add a cache step before that step and cache the folder primes:

```yml
- name: Cache Primes
  id: cache-primes
  uses: actions/cache@v3
  with:
    path: primes
    key: ${{ runner.os }}-primes
```

The key here is what has to be unique to determine if the cache has changed. In our example, we used the hash value of the packe-lock.json file. For prime numbers, we might have a different format for the operating system.

In the long-running operation, you can now check if the cache is valid and only execute it, when there is no hit for the current key:

```yml
- name: Generate Prime Numbers
  if: steps.cache-primes.outputs.cache-hit != 'true'
  run: |
    sleep 60
    echo "1 2 3..." > primes
```

This workflow would run the first time for the long-running operation and populate the file in the cache. If you run it a second time, it will load the file from the cache and omit the long-running step.

### There’s more...

A repository can store up to 10 GB of data in caches. Once that limit is reached, older files will be removed based on when they were last accessed. Caches that are not used for 1 week will also be cleaned up.

You can manage the cache under Actions | Caches (see Figure 6.22):

![](https://static.packt-cdn.com/products/9781835468944/graphics/image/B21738_06_221.jpg)<br>
Figure 6.22 – Managing the cache

The cache action (https://github.com/actions/cache) has good documentation and examples for most programming languages. You can also refer to the documentation when you want to implement caching (see https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows).

